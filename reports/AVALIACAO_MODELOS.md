# ðŸ“Š RelatÃ³rio de AvaliaÃ§Ã£o dos Modelos LSTM

**Tech Challenge Fase 4 - FIAP PÃ³s-Tech ML Engineering**

**Data**: Dezembro 2025

---

## ðŸ“‹ Resumo Executivo

Este relatÃ³rio apresenta os resultados da avaliaÃ§Ã£o dos modelos LSTM para previsÃ£o de preÃ§os de aÃ§Ãµes, desenvolvidos como parte do Tech Challenge Fase 4.

### Modelos Treinados

| SÃ­mbolo | Empresa | Dados | Ã‰pocas | Early Stop |
|---------|---------|-------|--------|------------|
| AAPL | Apple Inc. | 2018-2024 | 30 | âœ… Ã‰poca 30 |
| GOOGL | Alphabet Inc. | 2018-2024 | 21 | âœ… Ã‰poca 21 |
| NVDA | NVIDIA Corp. | 2018-2024 | 40 | âœ… Ã‰poca 40 |

---

## ðŸ“ˆ MÃ©tricas de Performance

### Tabela Comparativa

| SÃ­mbolo | RMSE ($) | MAE ($) | MAPE (%) | RÂ² | AcurÃ¡cia Direcional |
|---------|----------|---------|----------|-----|---------------------|
| **AAPL** | 38.46 | 37.49 | 16.20% | -2.05 | **55.02%** |
| **GOOGL** | 34.12 | 28.28 | **13.38%** | **0.27** | 52.60% |
| **NVDA** | 37.35 | 34.98 | 22.77% | -0.92 | 48.44% |

### InterpretaÃ§Ã£o das MÃ©tricas

#### MAPE (Mean Absolute Percentage Error)
- **< 10%**: Excelente
- **10-20%**: Bom/AceitÃ¡vel âœ… AAPL, GOOGL
- **20-30%**: RazoÃ¡vel
- **> 30%**: Precisa melhoria

#### AcurÃ¡cia Direcional
- **> 55%**: Bom âœ… AAPL
- **50-55%**: Levemente melhor que random âœ… GOOGL
- **< 50%**: NÃ£o melhor que random

#### RÂ² (Coeficiente de DeterminaÃ§Ã£o)
- **> 0**: Modelo explica variÃ¢ncia âœ… GOOGL
- **< 0**: Modelo pior que mÃ©dia (comum em data drift)

---

## ðŸ”¬ AnÃ¡lise Detalhada

### GOOGL (Melhor Desempenho)

```
ðŸ“Š MÃ©tricas GOOGL:
- RMSE: $34.12
- MAE: $28.28  
- MAPE: 13.38%
- RÂ²: 0.2702 âœ…
- AcurÃ¡cia Direcional: 52.60%
```

O modelo GOOGL apresentou o melhor desempenho geral:
- RÂ² positivo indica que o modelo captura parte da variÃ¢ncia
- MAPE abaixo de 15% Ã© considerado bom para previsÃµes financeiras
- AcurÃ¡cia direcional acima de 52% supera baseline random

### AAPL (Bom Desempenho com Data Drift)

```
ðŸ“Š MÃ©tricas AAPL:
- RMSE: $38.46
- MAE: $37.49
- MAPE: 16.20%
- RÂ²: -2.05 âš ï¸
- AcurÃ¡cia Direcional: 55.02% âœ…
```

O modelo AAPL tem a melhor acurÃ¡cia direcional (55%), mas RÂ² negativo devido ao **data drift**:
- PerÃ­odo de treino (2018-2023): AAPL ~$30-170
- PerÃ­odo de teste (2024-2025): AAPL ~$220-280
- A valorizaÃ§Ã£o significativa da aÃ§Ã£o afeta as mÃ©tricas de erro absoluto

### NVDA (Desafio: Alta Volatilidade)

```
ðŸ“Š MÃ©tricas NVDA:
- RMSE: $37.35
- MAE: $34.98
- MAPE: 22.77%
- RÂ²: -0.92
- AcurÃ¡cia Direcional: 48.44%
```

NVDA apresentou o maior desafio devido Ã  alta volatilidade do setor de IA:
- Stock de altÃ­ssima volatilidade (>3000% de valorizaÃ§Ã£o em 5 anos)
- PreÃ§os de teste muito distantes do treino
- MAPE ainda na faixa razoÃ¡vel (<25%)

---

## ðŸ—ï¸ Arquitetura do Modelo

### LSTM Melhorado

```
Arquitetura:
- LSTM Bidirecional: 3 camadas
- Hidden Size: 64 neurÃ´nios
- Dropout: 0.3
- Attention Mechanism: Pesos de atenÃ§Ã£o
- Loss Function: Huber Loss
- Optimizer: AdamW com weight decay
```

### Features Utilizadas (16 total)

| Categoria | Features |
|-----------|----------|
| PreÃ§os | open, high, low, close |
| Volume | volume, volume_ma_7 |
| MÃ©dias MÃ³veis | ma_7, ma_30, ma_90 |
| Volatilidade | volatility_7, volatility_30 |
| Momentum | momentum, roc_7, roc_30 |
| VariaÃ§Ã£o | price_change, pct_change |

### TÃ©cnicas de RegularizaÃ§Ã£o

1. **Early Stopping**: Parar treinamento quando val_loss nÃ£o melhora
2. **Learning Rate Scheduler**: ReduceLROnPlateau reduz LR em 50% quando estagna
3. **Gradient Clipping**: Max norm = 1.0 para evitar explosÃ£o de gradientes
4. **Dropout**: 30% para evitar overfitting
5. **Weight Decay**: 1e-5 no AdamW optimizer

---

## ðŸ“Š ValidaÃ§Ã£o Temporal (Walk-Forward)

```
Split dos Dados:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  70% TREINO  â”‚  15% VALIDAÃ‡ÃƒO  â”‚  15% TESTE  â”‚
â”‚  (2018-2022)  â”‚   (2022-2023)   â”‚  (2023-2024) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“              â†“               â†“
      Treinar      Early Stop       Avaliar
```

A validaÃ§Ã£o temporal garante:
- Nenhum vazamento de dados futuros
- SimulaÃ§Ã£o de cenÃ¡rio real de produÃ§Ã£o
- Early stopping baseado em dados de validaÃ§Ã£o

---

## ðŸŽ¯ ConclusÃµes

### Pontos Fortes

1. **Early Stopping Efetivo**: Todos os modelos pararam antes de overfitting
2. **MAPE AceitÃ¡vel**: Erros percentuais entre 13-23%
3. **AcurÃ¡cia Direcional**: AAPL 55% supera baseline significativamente
4. **RegularizaÃ§Ã£o**: TÃ©cnicas preveniram overfitting

### LimitaÃ§Ãµes Identificadas

1. **Data Drift**: Grandes valorizaÃ§Ãµes afetam RÂ² negativamente
2. **Volatilidade**: AÃ§Ãµes de alta volatilidade (NVDA) sÃ£o mais difÃ­ceis
3. **Horizonte de PrevisÃ£o**: Modelo prevÃª apenas 1 dia Ã  frente

### RecomendaÃ§Ãµes Futuras

1. **PrevisÃ£o de Retornos**: Usar retornos % ao invÃ©s de preÃ§os absolutos
2. **Retraining PeriÃ³dico**: Retreinar modelo mensalmente
3. **Ensemble**: Combinar mÃºltiplos modelos
4. **Features Adicionais**: Adicionar sentimento de notÃ­cias, dados macroeconÃ´micos

---

## ðŸ“š ReferÃªncias

- **Dataset**: Yahoo Finance via yfinance
- **Framework**: PyTorch 2.0+
- **PerÃ­odo**: Janeiro 2018 - Dezembro 2024
- **Ambiente**: CPU (Apple Silicon)

---

## ðŸ“ Arquivos Gerados

```
models/
â”œâ”€â”€ lstm_model_AAPL.pth    # Modelo treinado AAPL
â”œâ”€â”€ lstm_model_GOOGL.pth   # Modelo treinado GOOGL
â”œâ”€â”€ lstm_model_NVDA.pth    # Modelo treinado NVDA
â”œâ”€â”€ scaler_AAPL.pkl        # Preprocessor AAPL
â”œâ”€â”€ scaler_GOOGL.pkl       # Preprocessor GOOGL
â”œâ”€â”€ scaler_NVDA.pkl        # Preprocessor NVDA
â”œâ”€â”€ metadata_*.json        # Metadados de cada modelo
```

---

**Desenvolvido para**: Tech Challenge Fase 4 - FIAP PÃ³s-Tech ML Engineering
**Data de GeraÃ§Ã£o**: 02/12/2025

