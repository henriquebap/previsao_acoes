# üèõÔ∏è Arquitetura T√©cnica Detalhada

> Documento t√©cnico explicando a arquitetura do sistema de previs√£o de a√ß√µes

---

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura em Camadas](#arquitetura-em-camadas)
- [Fluxo de Dados](#fluxo-de-dados)
- [Componentes Principais](#componentes-principais)
- [Decis√µes de Design](#decis√µes-de-design)
- [Padr√µes Utilizados](#padr√µes-utilizados)
- [Performance e Escalabilidade](#performance-e-escalabilidade)

---

## üéØ Vis√£o Geral

O sistema segue uma **arquitetura em camadas** (layered architecture) com separa√ß√£o clara de responsabilidades:

```mermaid
graph TB
    subgraph "Presentation Layer"
        UI[Gradio UI]
        DOCS[API Docs]
    end
    
    subgraph "API Layer"
        GATEWAY[API Gateway<br/>FastAPI]
        MW[Middlewares<br/>CORS, Metrics, Logging]
        ROUTES[Routes<br/>Predictions, Data, Models]
    end
    
    subgraph "Business Logic Layer"
        PS[Prediction Service]
        TS[Training Service]
        DS[Data Service]
        MS[Model Service]
    end
    
    subgraph "Data Access Layer"
        DL[Data Loader<br/>yfinance]
        PP[Preprocessor<br/>sklearn]
        MR[Model Repository<br/>File System]
    end
    
    subgraph "ML Core"
        LSTM[LSTM Model<br/>PyTorch]
        TRAIN[Trainer<br/>Pipeline]
    end
    
    subgraph "Infrastructure"
        CONFIG[Configuration]
        LOG[Logging]
        MON[Monitoring]
    end
    
    UI --> GATEWAY
    DOCS --> GATEWAY
    GATEWAY --> MW
    MW --> ROUTES
    ROUTES --> PS
    ROUTES --> TS
    ROUTES --> DS
    ROUTES --> MS
    PS --> LSTM
    PS --> PP
    TS --> TRAIN
    TRAIN --> LSTM
    DS --> DL
    MS --> MR
    PP --> DL
    LSTM --> MR
    
    CONFIG -.-> GATEWAY
    CONFIG -.-> LSTM
    CONFIG -.-> DL
    LOG -.-> GATEWAY
    MON -.-> GATEWAY
    
    style GATEWAY fill:#e8f5e9
    style LSTM fill:#fff4e1
    style DL fill:#e1f5ff
```

---

## üìö Arquitetura em Camadas

### 1. Presentation Layer (Camada de Apresenta√ß√£o)

**Responsabilidade**: Interface com o usu√°rio

```mermaid
graph LR
    A[Web Browser] --> B[Gradio UI<br/>HuggingFace Spaces]
    C[CLI Tools] --> D[FastAPI Swagger<br/>localhost:8000/docs]
    E[HTTP Clients] --> F[REST API<br/>JSON responses]
    
    style B fill:#e1f5ff
    style D fill:#e8f5e9
    style F fill:#fff4e1
```

**Componentes**:
- **Gradio UI** (`app_gradio.py`): Interface gr√°fica para demos
- **Swagger/ReDoc**: Documenta√ß√£o interativa da API
- **HTTP Clients**: cURL, Python requests, etc.

### 2. API Layer (Camada de API)

**Responsabilidade**: Roteamento, valida√ß√£o, middlewares

```python
# src/api/main.py
app = FastAPI(
    title="Stock Price Prediction API",
    version="1.0.0"
)

# Middlewares
app.add_middleware(CORSMiddleware)
app.middleware("http")(add_process_time_and_metrics)

# Routes
app.include_router(predictions.router, prefix="/api/v1")
app.include_router(data.router, prefix="/api/v1")
app.include_router(models.router, prefix="/api/v1")
app.include_router(monitoring.router, prefix="/api/v1")
```

**Componentes**:
- **FastAPI App**: Entry point
- **CORS Middleware**: Cross-origin requests
- **Metrics Middleware**: Coleta de m√©tricas
- **Exception Handlers**: Tratamento de erros
- **Routers**: Organiza√ß√£o de endpoints

**Fluxo de Request:**

```mermaid
sequenceDiagram
    participant Client
    participant FastAPI
    participant CORS
    participant Metrics
    participant Route
    participant Service
    
    Client->>FastAPI: HTTP Request
    FastAPI->>CORS: Check origin
    CORS->>Metrics: Start timer
    Metrics->>Route: Validate & route
    Route->>Service: Business logic
    Service-->>Route: Result
    Route-->>Metrics: End timer
    Metrics-->>CORS: Add headers
    CORS-->>FastAPI: Response
    FastAPI-->>Client: HTTP Response
```

### 3. Business Logic Layer (Camada de L√≥gica de Neg√≥cio)

**Responsabilidade**: Orquestra√ß√£o e regras de neg√≥cio

```python
# src/api/routes/predictions.py
@router.post("/predict")
async def predict_stock_price(request: PredictionRequest):
    # 1. Validar request
    validate_symbol(request.symbol)
    
    # 2. Carregar modelo
    model = load_model(request.symbol)
    
    # 3. Obter dados
    data = get_recent_data(request.symbol)
    
    # 4. Preprocessar
    X = preprocessor.transform_for_prediction(data)
    
    # 5. Prever
    prediction = model.predict(X)
    
    # 6. Formatar resposta
    return format_prediction_response(prediction)
```

**Servi√ßos**:
- **Prediction Service**: Orquestra previs√µes
- **Training Service**: Orquestra treinamento
- **Data Service**: Gerencia dados
- **Model Service**: Gerencia modelos

### 4. Data Access Layer (Camada de Acesso a Dados)

**Responsabilidade**: Intera√ß√£o com fontes de dados

```python
# src/data/data_loader.py
class StockDataLoader:
    def load_stock_data(self, symbol, start_date, end_date):
        # Download do Yahoo Finance
        df = yf.download(symbol, start=start_date, end=end_date)
        
        # Valida√ß√£o
        self.validate_data(df)
        
        return df
```

**Componentes**:
- **DataLoader**: Coleta dados do Yahoo Finance
- **Preprocessor**: Transforma dados
- **Model Repository**: Salva/carrega modelos
- **Cache**: (futuro) Cache de dados

### 5. ML Core (N√∫cleo de Machine Learning)

**Responsabilidade**: Treinamento e infer√™ncia

```python
# src/models/lstm_model.py
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        output = self.fc(lstm_out[:, -1, :])
        return output
```

**Componentes**:
- **LSTMModel**: Arquitetura PyTorch
- **LSTMPredictor**: Wrapper para treino/infer√™ncia
- **Trainer**: Pipeline de treinamento

---

## üîÑ Fluxo de Dados

### Pipeline de Treinamento Completo

```mermaid
graph TB
    START([In√≠cio]) --> LOAD[Load Data<br/>yfinance]
    LOAD --> VALIDATE[Validate Data<br/>check nulls, ranges]
    VALIDATE --> FEATURES[Create Features<br/>16 features]
    FEATURES --> NORMALIZE[Normalize<br/>MinMaxScaler 0-1]
    NORMALIZE --> SEQUENCE[Create Sequences<br/>60 days windows]
    SEQUENCE --> SPLIT[Train/Val Split<br/>80/20]
    
    SPLIT --> INIT[Initialize LSTM<br/>input_size=16]
    INIT --> TRAIN_LOOP{Training Loop<br/>50 epochs}
    
    TRAIN_LOOP --> FORWARD[Forward Pass<br/>predictions]
    FORWARD --> LOSS[Calculate Loss<br/>MSE]
    LOSS --> BACKWARD[Backward Pass<br/>gradients]
    BACKWARD --> UPDATE[Update Weights<br/>Adam optimizer]
    UPDATE --> VALIDATE_EPOCH[Validate<br/>validation set]
    VALIDATE_EPOCH --> TRAIN_LOOP
    
    TRAIN_LOOP --> |Done| EVALUATE[Evaluate<br/>RMSE, MAE, MAPE]
    EVALUATE --> SAVE_MODEL[Save Model<br/>.pth]
    SAVE_MODEL --> SAVE_PREP[Save Preprocessor<br/>.pkl]
    SAVE_PREP --> SAVE_META[Save Metadata<br/>.json]
    SAVE_META --> END([Fim])
    
    style START fill:#e8f5e9
    style TRAIN_LOOP fill:#fff4e1
    style END fill:#e8f5e9
```

### Pipeline de Infer√™ncia (Predi√ß√£o)

```mermaid
graph TB
    START([API Request]) --> VALIDATE[Validate Symbol<br/>format check]
    VALIDATE --> CHECK{Model<br/>exists?}
    CHECK -->|No| ERROR1[Return 404<br/>Model not found]
    CHECK -->|Yes| LOAD_MODEL[Load Model<br/>.pth file]
    
    LOAD_MODEL --> LOAD_PREP[Load Preprocessor<br/>.pkl file]
    LOAD_PREP --> GET_DATA[Get Recent Data<br/>60 days from Yahoo]
    
    GET_DATA --> CHECK_DATA{Sufficient<br/>data?}
    CHECK_DATA -->|No| ERROR2[Return 400<br/>Insufficient data]
    CHECK_DATA -->|Yes| PREP_FEATURES[Create Features<br/>same 16 features]
    
    PREP_FEATURES --> NORMALIZE_DATA[Normalize<br/>using saved scaler]
    NORMALIZE_DATA --> CREATE_SEQ[Create Sequence<br/>last 60 days]
    CREATE_SEQ --> PREDICT[Model Prediction<br/>LSTM forward]
    
    PREDICT --> INVERSE[Inverse Transform<br/>denormalize]
    INVERSE --> CALC[Calculate Change<br/>vs current price]
    CALC --> FORMAT[Format Response<br/>JSON]
    FORMAT --> END([Return Response])
    
    ERROR1 --> END
    ERROR2 --> END
    
    style START fill:#e1f5ff
    style PREDICT fill:#fff4e1
    style END fill:#e8f5e9
```

---

## üß© Componentes Principais

### 1. DataLoader (Coleta de Dados)

**Responsabilidades**:
- Download de dados do Yahoo Finance
- Valida√ß√£o de dados
- Padroniza√ß√£o de formato
- Tratamento de erros

**Tecnologias**:
- `yfinance`: API do Yahoo Finance
- `pandas`: Manipula√ß√£o de DataFrames

**Principais M√©todos**:

```python
class StockDataLoader:
    def load_stock_data(symbol, start_date, end_date) -> DataFrame
    def validate_data(df) -> bool
    def get_latest_price(symbol) -> dict
```

**Features do DataFrame**:
```python
['timestamp', 'open', 'high', 'low', 'close', 'volume',
 'year', 'month', 'day', 'day_of_week', 'symbol']
```

### 2. Preprocessor (Feature Engineering)

**Responsabilidades**:
- Criar features t√©cnicas
- Normalizar dados
- Criar sequ√™ncias para LSTM
- Inverse transform para previs√µes

**Features Criadas**:

| Categoria | Feature | C√°lculo |
|-----------|---------|---------|
| **Price Changes** | `price_change` | `close.pct_change()` |
| | `high_low_pct` | `(high - low) / low` |
| | `close_open_pct` | `(close - open) / open` |
| **Moving Averages** | `ma_7` | `close.rolling(7).mean()` |
| | `ma_30` | `close.rolling(30).mean()` |
| | `ma_90` | `close.rolling(90).mean()` |
| **Volatility** | `volatility_7` | `close.rolling(7).std()` |
| | `volatility_30` | `close.rolling(30).std()` |
| **Volume** | `volume_change` | `volume.pct_change()` |
| | `volume_ma_7` | `volume.rolling(7).mean()` |
| **Momentum** | `momentum` | `close - close.shift(4)` |

**Principais M√©todos**:

```python
class StockDataPreprocessor:
    def fit_transform(df) -> (X, y, df_processed)
    def transform(df) -> (X, y, df_processed)
    def transform_for_prediction(df) -> X
    def inverse_transform_target(scaled_value) -> float
    def save(path)
    def load(path) -> StockDataPreprocessor
```

### 3. LSTM Model (Modelo Neural)

**Arquitetura**:

```python
LSTMModel(
  (lstm): LSTM(16, 50, num_layers=2, batch_first=True, dropout=0.2)
  (fc): Linear(in_features=50, out_features=1, bias=True)
  (dropout): Dropout(p=0.2, inplace=False)
)
```

**Par√¢metros**:
- **Input Size**: 16 features
- **Hidden Size**: 50 neurons
- **Num Layers**: 2 camadas LSTM
- **Dropout**: 0.2 (20% de regulariza√ß√£o)
- **Output Size**: 1 (pre√ßo previsto)

**Shape Flow**:

```
Input:  [batch_size, 60, 16]  # 60 dias, 16 features
                ‚Üì
LSTM:   [batch_size, 60, 50]  # 50 hidden units
                ‚Üì
Last:   [batch_size, 50]      # √∫ltimo timestep
                ‚Üì
Dropout: [batch_size, 50]      # regulariza√ß√£o
                ‚Üì
FC:     [batch_size, 1]        # previs√£o final
```

**Principais M√©todos**:

```python
class LSTMPredictor:
    def fit(X_train, y_train, X_val, y_val, epochs, batch_size)
    def train_epoch(X_train, y_train, batch_size) -> loss
    def validate(X_val, y_val, batch_size) -> loss
    def predict(X) -> predictions
    def save(path)
    def load(path) -> LSTMPredictor
```

### 4. Trainer (Orquestrador de Treinamento)

**Responsabilidades**:
- Carregar dados
- Preprocessar
- Treinar modelo
- Avaliar performance
- Salvar artifacts

**Pipeline**:

```python
class ModelTrainer:
    def run_training_pipeline(start_date, end_date):
        # 1. Load data
        df = self.load_data(start_date, end_date)
        
        # 2. Prepare data
        X_train, y_train, X_test, y_test = self.prepare_data(df)
        
        # 3. Train model
        self.train_model(X_train, y_train, X_val, y_val)
        
        # 4. Evaluate
        metrics = self.evaluate_model(X_test, y_test)
        
        # 5. Save
        self.save_model()
        
        return metrics
```

### 5. FastAPI Routes (Endpoints)

**Organiza√ß√£o**:

```
src/api/routes/
‚îú‚îÄ‚îÄ predictions.py     # POST /predict, /predict/batch
‚îú‚îÄ‚îÄ data.py           # GET /stocks/{symbol}/historical
‚îú‚îÄ‚îÄ models.py         # POST /models/train
‚îî‚îÄ‚îÄ monitoring.py     # GET /health, /metrics
```

**Exemplo de Route**:

```python
# src/api/routes/predictions.py
from fastapi import APIRouter, HTTPException
from src.api.schemas import PredictionRequest, PredictionResponse

router = APIRouter()

@router.post("/predict", response_model=PredictionResponse)
async def predict_stock_price(request: PredictionRequest):
    """Fazer previs√£o de pre√ßo de a√ß√£o."""
    try:
        # Business logic
        result = prediction_service.predict(
            symbol=request.symbol,
            days_ahead=request.days_ahead
        )
        return result
    except ModelNotFoundError:
        raise HTTPException(status_code=404, detail="Model not found")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## üé® Decis√µes de Design

### 1. Por que FastAPI?

**Alternativas consideradas**: Flask, Django REST Framework

**Escolha: FastAPI**

‚úÖ **Vantagens**:
- Performance alta (baseado em Starlette/Uvicorn)
- Valida√ß√£o autom√°tica com Pydantic
- Documenta√ß√£o autom√°tica (Swagger/OpenAPI)
- Type hints nativos
- Async/await support

‚ùå **Desvantagens**:
- Comunidade menor que Flask
- Menos plugins/extensions

### 2. Por que PyTorch?

**Alternativas consideradas**: TensorFlow/Keras

**Escolha: PyTorch**

‚úÖ **Vantagens**:
- Mais pythonic e intuitivo
- Debug mais f√°cil (execu√ß√£o din√¢mica)
- Research-friendly
- Boa documenta√ß√£o

‚ùå **Desvantagens**:
- Deploy pode ser mais pesado
- Menos ferramentas prontas

### 3. Por que yfinance?

**Alternativas consideradas**: Alpha Vantage, IEX Cloud

**Escolha: yfinance**

‚úÖ **Vantagens**:
- Gratuito e sem API key
- Dados confi√°veis (Yahoo Finance)
- F√°cil de usar
- Hist√≥rico extenso

‚ùå **Desvantagens**:
- N√£o oficial (pode quebrar)
- Rate limits
- Dados atrasados (15min)

### 4. Arquitetura em Camadas vs Microservices

**Escolha: Arquitetura em Camadas (Monolito Modular)**

‚úÖ **Vantagens**:
- Mais simples de desenvolver e debugar
- Menos overhead de rede
- Suficiente para escala do projeto
- Deploy mais f√°cil

‚ùå **Quando usar Microservices**:
- Necessidade de escalar componentes independentemente
- M√∫ltiplas equipes trabalhando
- Requisitos de disponibilidade diferentes

---

## üîß Padr√µes Utilizados

### 1. Repository Pattern

```python
# Abstra√ß√£o do acesso a dados
class ModelRepository:
    def save(model, path):
        torch.save(model.state_dict(), path)
    
    def load(path):
        model = LSTMModel()
        model.load_state_dict(torch.load(path))
        return model
```

### 2. Factory Pattern

```python
# Cria√ß√£o de modelos
class ModelFactory:
    @staticmethod
    def create_model(model_type, **kwargs):
        if model_type == "lstm":
            return LSTMPredictor(**kwargs)
        elif model_type == "gru":
            return GRUPredictor(**kwargs)
```

### 3. Dependency Injection

```python
# Inje√ß√£o de depend√™ncias
class PredictionService:
    def __init__(self, model_loader, data_loader, preprocessor):
        self.model_loader = model_loader
        self.data_loader = data_loader
        self.preprocessor = preprocessor
```

### 4. Strategy Pattern

```python
# Diferentes estrat√©gias de normaliza√ß√£o
class NormalizationStrategy(ABC):
    @abstractmethod
    def normalize(self, data): pass

class MinMaxNormalization(NormalizationStrategy):
    def normalize(self, data):
        return (data - data.min()) / (data.max() - data.min())

class StandardNormalization(NormalizationStrategy):
    def normalize(self, data):
        return (data - data.mean()) / data.std()
```

---

## üìä Performance e Escalabilidade

### M√©tricas de Performance Atuais

```mermaid
graph LR
    subgraph "Lat√™ncias"
        P1[Prediction<br/>~200ms]
        T1[Training<br/>~15min]
        D1[Data Load<br/>~5s]
    end
    
    subgraph "Throughput"
        R1[~50 req/s<br/>single worker]
        R2[~200 req/s<br/>4 workers]
    end
    
    subgraph "Recursos"
        M1[Memory<br/>~500MB]
        C1[CPU<br/>~30%]
    end
    
    style P1 fill:#e8f5e9
    style T1 fill:#fff4e1
    style D1 fill:#e1f5ff
```

### Bottlenecks Identificados

1. **Data Loading**: Download do Yahoo Finance (~5s)
   - **Solu√ß√£o**: Cache com Redis ou DB

2. **Model Loading**: Carregar do disco a cada request
   - **Solu√ß√£o**: Manter modelos em mem√≥ria

3. **Single Thread Processing**
   - **Solu√ß√£o**: M√∫ltiplos workers Uvicorn

### Otimiza√ß√µes Implementadas

```python
# 1. Caching de modelos em mem√≥ria
from functools import lru_cache

@lru_cache(maxsize=10)
def load_model(symbol):
    return LSTMPredictor.load(get_model_path(symbol))

# 2. Batch predictions
def predict_batch(symbols):
    # Processa m√∫ltiplas previs√µes em paralelo
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(predict_single, s) for s in symbols]
        results = [f.result() for f in futures]
    return results

# 3. Async endpoints
@router.post("/predict")
async def predict(request: PredictionRequest):
    # N√£o bloqueia outras requisi√ß√µes
    result = await run_in_threadpool(prediction_service.predict, request)
    return result
```

### Estrat√©gias de Escalabilidade

#### Horizontal Scaling

```mermaid
graph TB
    LB[Load Balancer<br/>Nginx/Railway] --> API1[API Instance 1<br/>4 workers]
    LB --> API2[API Instance 2<br/>4 workers]
    LB --> API3[API Instance 3<br/>4 workers]
    
    API1 --> CACHE[Redis Cache<br/>Shared]
    API2 --> CACHE
    API3 --> CACHE
    
    API1 --> DB[PostgreSQL<br/>Shared]
    API2 --> DB
    API3 --> DB
    
    style LB fill:#e8f5e9
    style CACHE fill:#fff4e1
    style DB fill:#e1f5ff
```

#### Vertical Scaling

```yaml
# railway.toml
[deploy]
  numReplicas = 1
  sleepApplication = false
  restartPolicyType = "ON_FAILURE"

[resources]
  memoryGB = 2
  vCPU = 2
```

---

## üîç Monitoramento de Arquitetura

### M√©tricas Coletadas

```python
# src/utils/monitoring.py
from prometheus_client import Counter, Histogram, Gauge

# Contadores
api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

# Histogramas (lat√™ncia)
request_duration_seconds = Histogram(
    'request_duration_seconds',
    'Request duration in seconds',
    ['endpoint']
)

# Gauges (valores atuais)
active_requests = Gauge(
    'active_requests',
    'Number of active requests'
)
```

### Logs Estruturados

```python
# Logs com contexto
logger.info(
    "Prediction made",
    extra={
        "symbol": "AAPL",
        "predicted_price": 185.50,
        "duration_ms": 234,
        "model_version": "v1.0"
    }
)
```

---

## üìö Refer√™ncias T√©cnicas

### Papers e Artigos

1. **LSTM**: [Understanding LSTM Networks - Colah's Blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
2. **Time Series Forecasting**: [Deep Learning for Time Series Forecasting - Brownlee](https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/)
3. **Financial ML**: [Advances in Financial Machine Learning - Marcos Lopez de Prado](https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086)

### Documenta√ß√£o

- [PyTorch LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)
- [FastAPI](https://fastapi.tiangolo.com/)
- [yfinance](https://github.com/ranaroussi/yfinance)
- [Prometheus Python Client](https://github.com/prometheus/client_python)

---

**Desenvolvido para Tech Challenge Fase 4 - FIAP**

*√öltima atualiza√ß√£o: Dezembro 2024*

