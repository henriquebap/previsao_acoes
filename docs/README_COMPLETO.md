# ğŸ“ˆ Sistema de PrevisÃ£o de PreÃ§os de AÃ§Ãµes com LSTM

> **Tech Challenge Fase 4 - FIAP PÃ³s-Tech Machine Learning Engineering**
> 
> Um projeto completo de ML Engineering: da coleta de dados ao deploy em produÃ§Ã£o

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral do Projeto](#-visÃ£o-geral-do-projeto)
- [Arquitetura do Sistema](#-arquitetura-do-sistema)
- [Como Funciona o LSTM](#-como-funciona-o-lstm)
- [Fluxos do Sistema](#-fluxos-do-sistema)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [Como Usar](#-como-usar)
- [API Endpoints](#-api-endpoints)
- [Deploy](#-deploy)
- [TÃ©cnicas de ML Engineering](#-tÃ©cnicas-de-ml-engineering)
- [Monitoramento e Testes](#-monitoramento-e-testes)
- [Resultados e MÃ©tricas](#-resultados-e-mÃ©tricas)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ VisÃ£o Geral do Projeto

Este projeto Ã© um **sistema completo de Machine Learning** para previsÃ£o de preÃ§os de aÃ§Ãµes, desenvolvido seguindo as melhores prÃ¡ticas de ML Engineering. O objetivo Ã© aplicar conhecimentos prÃ¡ticos de forma **simples, replicÃ¡vel e production-ready**.

### O que o Sistema Faz?

1. **Coleta dados** histÃ³ricos de aÃ§Ãµes do Yahoo Finance
2. **Processa e cria features** tÃ©cnicas (mÃ©dias mÃ³veis, volatilidade, etc.)
3. **Treina um modelo LSTM** para capturar padrÃµes temporais
4. **Disponibiliza previsÃµes** via API RESTful
5. **Monitora performance** em tempo real
6. **Deploy em produÃ§Ã£o** com Docker e Railway

### Por que LSTM?

**LSTM (Long Short-Term Memory)** Ã© uma rede neural recorrente ideal para sÃ©ries temporais porque:

- âœ… **MemÃ³ria de longo prazo**: Consegue "lembrar" padrÃµes de dias/semanas atrÃ¡s
- âœ… **Evita vanishing gradient**: MantÃ©m o aprendizado mesmo com sequÃªncias longas
- âœ… **PadrÃ£o da indÃºstria**: Amplamente usado em finanÃ§as e previsÃµes
- âœ… **Balanceamento**: NÃ£o Ã© muito simples nem muito complexo para aprender

---

## ğŸ—ï¸ Arquitetura do Sistema

### VisÃ£o Geral de Alto NÃ­vel

```mermaid
graph TB
    subgraph "1. Data Collection"
        YF[Yahoo Finance API]
    end
    
    subgraph "2. Data Processing"
        DL[Data Loader<br/>yfinance]
        FE[Feature Engineering<br/>16 features]
        PP[Preprocessor<br/>MinMaxScaler]
    end
    
    subgraph "3. Model Training"
        LSTM[LSTM Model<br/>PyTorch]
        TR[Trainer<br/>Epochs, Validation]
    end
    
    subgraph "4. Model Storage"
        MS[Model Files<br/>.pth + .pkl]
        META[Metadata<br/>JSON]
    end
    
    subgraph "5. API Layer"
        FA[FastAPI<br/>REST Endpoints]
    end
    
    subgraph "6. Monitoring"
        PROM[Prometheus<br/>Metrics]
        LOG[Loguru<br/>Logs]
    end
    
    subgraph "7. Deployment"
        DOCK[Docker<br/>Container]
        RAIL[Railway<br/>Cloud]
        HF[HuggingFace<br/>UI Demo]
    end
    
    YF --> DL
    DL --> FE
    FE --> PP
    PP --> LSTM
    LSTM --> TR
    TR --> MS
    TR --> META
    MS --> FA
    FA --> PROM
    FA --> LOG
    FA --> DOCK
    DOCK --> RAIL
    FA --> HF
    
    style YF fill:#e1f5ff
    style LSTM fill:#fff4e1
    style FA fill:#e8f5e9
    style RAIL fill:#f3e5f5
```

### Arquitetura de Componentes

```mermaid
graph LR
    subgraph "Frontend Layer"
        UI[Gradio UI<br/>HuggingFace Spaces]
    end
    
    subgraph "API Layer"
        API[FastAPI<br/>REST API]
        CORS[CORS Middleware]
        VAL[Validation<br/>Pydantic]
    end
    
    subgraph "Business Logic"
        PRED[Prediction Service]
        TRAIN[Training Service]
        DATA[Data Service]
    end
    
    subgraph "Data Layer"
        YAHOO[Yahoo Finance<br/>yfinance]
        FILES[File System<br/>models/, data/]
    end
    
    subgraph "ML Core"
        MODEL[LSTM Model<br/>PyTorch]
        PREP[Preprocessor<br/>sklearn]
    end
    
    UI --> API
    API --> CORS
    CORS --> VAL
    VAL --> PRED
    VAL --> TRAIN
    VAL --> DATA
    PRED --> MODEL
    PRED --> PREP
    TRAIN --> MODEL
    TRAIN --> PREP
    DATA --> YAHOO
    MODEL --> FILES
    PREP --> FILES
    
    style UI fill:#e1f5ff
    style API fill:#e8f5e9
    style MODEL fill:#fff4e1
    style YAHOO fill:#f3e5f5
```

---

## ğŸ§  Como Funciona o LSTM

### Estrutura do Modelo

```mermaid
graph TB
    subgraph "Input Layer"
        IN[SequÃªncia de 60 dias<br/>16 features por dia<br/>Shape: batch, 60, 16]
    end
    
    subgraph "LSTM Layers"
        L1[LSTM Layer 1<br/>50 hidden units<br/>Bidirectional]
        DROP1[Dropout 20%<br/>RegularizaÃ§Ã£o]
        L2[LSTM Layer 2<br/>50 hidden units<br/>Bidirectional]
        DROP2[Dropout 20%<br/>RegularizaÃ§Ã£o]
    end
    
    subgraph "Output Layer"
        FC[Fully Connected<br/>50 â†’ 1]
        OUT[PrevisÃ£o de PreÃ§o<br/>Single value]
    end
    
    IN --> L1
    L1 --> DROP1
    DROP1 --> L2
    L2 --> DROP2
    DROP2 --> FC
    FC --> OUT
    
    style IN fill:#e1f5ff
    style L1 fill:#fff4e1
    style L2 fill:#fff4e1
    style OUT fill:#e8f5e9
```

### Features Utilizadas (16 no total)

```mermaid
mindmap
  root((Features<br/>16 total))
    PreÃ§os
      Open
      High
      Low
      Close
      Volume
    VariaÃ§Ãµes
      Price Change %
      High-Low %
      Close-Open %
      Volume Change %
    MÃ©dias MÃ³veis
      MA 7 dias
      MA 30 dias
      MA 90 dias
    Volatilidade
      Vol 7 dias
      Vol 30 dias
    Momentum
      Momentum 4 dias
      Volume MA 7 dias
```

### Por que 16 Features?

| Categoria | Features | Motivo |
|-----------|----------|--------|
| **PreÃ§os OHLCV** | 5 features | Dados base essenciais |
| **VariaÃ§Ãµes %** | 4 features | Captura movimentos relativos |
| **MÃ©dias MÃ³veis** | 3 features | Identifica tendÃªncias |
| **Volatilidade** | 2 features | Mede incerteza/risco |
| **Momentum** | 2 features | Captura forÃ§a da tendÃªncia |

---

## ğŸ”„ Fluxos do Sistema

### 1. Fluxo de Treinamento

```mermaid
sequenceDiagram
    participant User
    participant Script as train_model.py
    participant Loader as DataLoader
    participant Yahoo as Yahoo Finance
    participant Prep as Preprocessor
    participant Model as LSTM Model
    participant Trainer as ModelTrainer
    participant Storage as File System
    
    User->>Script: python train_model.py AAPL
    Script->>Loader: load_stock_data(AAPL)
    Loader->>Yahoo: Download historical data
    Yahoo-->>Loader: OHLCV data
    Loader-->>Script: DataFrame
    
    Script->>Prep: fit_transform(df)
    Prep->>Prep: Create 16 features
    Prep->>Prep: Normalize (MinMaxScaler)
    Prep->>Prep: Create sequences (60 days)
    Prep-->>Script: X_train, y_train, X_test, y_test
    
    Script->>Model: Initialize LSTM
    Script->>Trainer: Train for N epochs
    
    loop Epochs
        Trainer->>Model: Forward pass
        Model-->>Trainer: Predictions
        Trainer->>Trainer: Calculate loss
        Trainer->>Model: Backward pass (update weights)
    end
    
    Trainer-->>Script: Training complete
    
    Script->>Trainer: Evaluate model
    Trainer->>Model: Predict on test set
    Trainer->>Trainer: Calculate metrics (RMSE, MAE, MAPE, RÂ²)
    Trainer-->>Script: Metrics
    
    Script->>Storage: Save model (.pth)
    Script->>Storage: Save preprocessor (.pkl)
    Script->>Storage: Save metadata (.json)
    
    Storage-->>User: âœ… Training complete!
```

### 2. Fluxo de PrediÃ§Ã£o

```mermaid
sequenceDiagram
    participant Client
    participant API as FastAPI
    participant Route as Prediction Route
    participant Loader as DataLoader
    participant Yahoo as Yahoo Finance
    participant Prep as Preprocessor
    participant Model as LSTM Model
    participant Storage as File System
    
    Client->>API: POST /api/v1/predict<br/>{symbol: AAPL, days_ahead: 1}
    API->>Route: Validate request
    
    Route->>Storage: Load model (AAPL)
    Storage-->>Route: lstm_model_AAPL.pth
    
    Route->>Storage: Load preprocessor
    Storage-->>Route: scaler_AAPL.pkl
    
    Route->>Loader: Get latest 60 days
    Loader->>Yahoo: Download recent data
    Yahoo-->>Loader: Historical data
    Loader-->>Route: Last 60 days
    
    Route->>Prep: transform_for_prediction(data)
    Prep->>Prep: Create features
    Prep->>Prep: Normalize
    Prep-->>Route: X_sequence [1, 60, 16]
    
    Route->>Model: predict(X_sequence)
    Model->>Model: Forward pass through LSTM
    Model-->>Route: Scaled prediction
    
    Route->>Prep: inverse_transform
    Prep-->>Route: Actual price prediction
    
    Route->>Route: Calculate change %
    Route-->>API: Response JSON
    API-->>Client: {<br/>  predicted_price: 185.50,<br/>  current_price: 183.20,<br/>  change_pct: 1.25<br/>}
```

### 3. Fluxo da API Completo

```mermaid
graph TB
    subgraph "Client Layer"
        WEB[Web Browser]
        CLI[CLI/cURL]
        UI[Gradio UI]
    end
    
    subgraph "API Gateway"
        ENTRY[FastAPI Entry Point]
        CORS[CORS Middleware]
        METRICS[Metrics Middleware]
    end
    
    subgraph "Routes"
        PRED[/predict<br/>Predictions]
        DATA[/stocks<br/>Data]
        MODEL[/models<br/>Model Mgmt]
        HEALTH[/health<br/>Monitoring]
    end
    
    subgraph "Services"
        PS[Prediction Service]
        DS[Data Service]
        MS[Model Service]
        MON[Monitoring Service]
    end
    
    subgraph "External"
        YF[Yahoo Finance]
        FS[File System]
        PROM[Prometheus]
    end
    
    WEB --> ENTRY
    CLI --> ENTRY
    UI --> ENTRY
    
    ENTRY --> CORS
    CORS --> METRICS
    METRICS --> PRED
    METRICS --> DATA
    METRICS --> MODEL
    METRICS --> HEALTH
    
    PRED --> PS
    DATA --> DS
    MODEL --> MS
    HEALTH --> MON
    
    PS --> FS
    DS --> YF
    MS --> FS
    MON --> PROM
    
    style ENTRY fill:#e8f5e9
    style PS fill:#fff4e1
    style YF fill:#e1f5ff
```

### 4. Pipeline de Deploy

```mermaid
graph LR
    subgraph "Development"
        CODE[Code Changes]
        TEST[Run Tests]
        COMMIT[Git Commit]
    end
    
    subgraph "CI/CD - GitHub Actions"
        BUILD[Build Docker]
        LINT[Lint & Format]
        PYTEST[Run Tests]
        PUSH[Push Image]
    end
    
    subgraph "Production"
        RAIL[Railway Deploy]
        HEALTH[Health Checks]
        LIVE[Live API]
    end
    
    subgraph "Monitoring"
        LOGS[View Logs]
        METRICS[Track Metrics]
        ALERTS[Alerts]
    end
    
    CODE --> TEST
    TEST --> COMMIT
    COMMIT --> BUILD
    BUILD --> LINT
    LINT --> PYTEST
    PYTEST --> PUSH
    PUSH --> RAIL
    RAIL --> HEALTH
    HEALTH --> LIVE
    LIVE --> LOGS
    LIVE --> METRICS
    METRICS --> ALERTS
    
    style CODE fill:#e1f5ff
    style RAIL fill:#e8f5e9
    style LIVE fill:#fff4e1
```

---

## ğŸ“ Estrutura do Projeto

```
previsao_acoes/
â”‚
â”œâ”€â”€ ğŸ“Š src/                          # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ api/                         # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py                  # Entry point da API
â”‚   â”‚   â”œâ”€â”€ schemas.py               # Modelos Pydantic (validaÃ§Ã£o)
â”‚   â”‚   â””â”€â”€ routes/                  # Endpoints organizados
â”‚   â”‚       â”œâ”€â”€ predictions.py       # POST /predict, /predict/batch
â”‚   â”‚       â”œâ”€â”€ data.py              # GET /stocks/{symbol}/historical
â”‚   â”‚       â”œâ”€â”€ models.py            # POST /models/train, GET /models/status
â”‚   â”‚       â””â”€â”€ monitoring.py        # GET /metrics, /health
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                        # Coleta e processamento de dados
â”‚   â”‚   â”œâ”€â”€ data_loader.py           # Download via yfinance
â”‚   â”‚   â””â”€â”€ preprocessor.py          # Feature engineering + normalizaÃ§Ã£o
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # Modelo LSTM
â”‚   â”‚   â””â”€â”€ lstm_model.py            # Arquitetura PyTorch
â”‚   â”‚
â”‚   â”œâ”€â”€ training/                    # Pipeline de treinamento
â”‚   â”‚   â””â”€â”€ trainer.py               # Orquestra todo o treino
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # UtilitÃ¡rios
â”‚       â”œâ”€â”€ logger.py                # ConfiguraÃ§Ã£o de logs
â”‚       â””â”€â”€ monitoring.py            # MÃ©tricas Prometheus
â”‚
â”œâ”€â”€ ğŸ§ª tests/                        # Testes automatizados
â”‚   â”œâ”€â”€ test_api.py                  # Testa endpoints
â”‚   â”œâ”€â”€ test_data_loader.py          # Testa coleta de dados
â”‚   â”œâ”€â”€ test_preprocessor.py         # Testa features
â”‚   â””â”€â”€ test_model.py                # Testa LSTM
â”‚
â”œâ”€â”€ ğŸ”§ config/                       # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                  # Centralizadas (variÃ¡veis de ambiente)
â”‚
â”œâ”€â”€ ğŸ“œ scripts/                      # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ train_model.py               # CLI para treinar modelos
â”‚   â”œâ”€â”€ scheduled_training.sh        # Script para cron jobs
â”‚   â””â”€â”€ setup_cron.sh                # Configura treinamento agendado
â”‚
â”œâ”€â”€ ğŸ’¾ data/                         # Dados (gerado em runtime)
â”‚   â”œâ”€â”€ raw/                         # Dados brutos do Yahoo Finance
â”‚   â””â”€â”€ processed/                   # Dados processados
â”‚
â”œâ”€â”€ ğŸ¤– models/                       # Modelos treinados (gerado)
â”‚   â”œâ”€â”€ lstm_model_AAPL.pth          # Modelo treinado
â”‚   â”œâ”€â”€ scaler_AAPL.pkl              # Preprocessador
â”‚   â””â”€â”€ metadata_AAPL.json           # MÃ©tricas e info
â”‚
â”œâ”€â”€ ğŸ“ logs/                         # Logs da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ app_2024-12-02.log           # Logs gerais
â”‚   â””â”€â”€ errors_2024-12-02.log        # Apenas erros
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_exploratory_data_analysis.ipynb
â”‚   â””â”€â”€ 02_entendendo_lstm_passo_a_passo.ipynb
â”‚
â”œâ”€â”€ ğŸ³ Docker Files
â”‚   â”œâ”€â”€ Dockerfile                   # Multi-stage build
â”‚   â”œâ”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o
â”‚   â””â”€â”€ .dockerignore               # OtimizaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸš€ Deploy Files
â”‚   â”œâ”€â”€ railway.json                 # Config Railway
â”‚   â””â”€â”€ app_gradio.py                # UI para HuggingFace Spaces
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o principal
â”‚   â”œâ”€â”€ QUICKSTART.md                # Guia rÃ¡pido (5 min)
â”‚   â”œâ”€â”€ DEPLOYMENT.md                # Guia de deploy
â”‚   â””â”€â”€ PROJECT_SUMMARY.md           # Resumo executivo
â”‚
â”œâ”€â”€ âš™ï¸ Configuration Files
â”‚   â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”‚   â”œâ”€â”€ pytest.ini                   # Config de testes
â”‚   â”œâ”€â”€ .gitignore                   # Git ignore
â”‚   â””â”€â”€ .env.example                 # Template de variÃ¡veis
â”‚
â””â”€â”€ ğŸ”„ CI/CD
    â””â”€â”€ .github/
        â””â”€â”€ workflows/
            â””â”€â”€ ci-cd.yml            # GitHub Actions
```

### ExplicaÃ§Ã£o dos Principais Arquivos

| Arquivo | FunÃ§Ã£o | Por que Ã© importante? |
|---------|--------|----------------------|
| `src/models/lstm_model.py` | Arquitetura LSTM em PyTorch | **CÃ©rebro do sistema** - define como o modelo aprende |
| `src/training/trainer.py` | Orquestra treinamento completo | **Pipeline ML** - coleta, treina, avalia, salva |
| `src/data/preprocessor.py` | Cria features e normaliza | **Feature Engineering** - transforma dados brutos em features Ãºteis |
| `src/api/main.py` | Entry point da API | **Interface** - expÃµe o modelo como serviÃ§o |
| `scripts/train_model.py` | CLI para treinar | **AutomaÃ§Ã£o** - permite treinar via comando ou cron |
| `config/settings.py` | ConfiguraÃ§Ãµes centralizadas | **Flexibilidade** - muda comportamento sem alterar cÃ³digo |
| `Dockerfile` | ContainerizaÃ§Ã£o | **Portabilidade** - roda igual em qualquer lugar |

---

## ğŸ”§ Tecnologias Utilizadas

### Core ML & Data Science

```mermaid
graph LR
    subgraph "Data Collection"
        YF[yfinance<br/>Yahoo Finance API]
    end
    
    subgraph "Data Processing"
        NP[NumPy<br/>Arrays numÃ©ricos]
        PD[Pandas<br/>DataFrames]
        SK[scikit-learn<br/>Preprocessing]
    end
    
    subgraph "Deep Learning"
        PT[PyTorch<br/>LSTM Model]
    end
    
    subgraph "API"
        FA[FastAPI<br/>REST API]
        PY[Pydantic<br/>Validation]
    end
    
    YF --> PD
    PD --> NP
    NP --> SK
    SK --> PT
    PT --> FA
    FA --> PY
    
    style PT fill:#fff4e1
    style FA fill:#e8f5e9
```

### Detalhamento das Tecnologias

| Tecnologia | VersÃ£o | Uso no Projeto | Por que escolhemos? |
|------------|--------|----------------|---------------------|
| **Python** | 3.10 | Linguagem base | PadrÃ£o da indÃºstria ML |
| **PyTorch** | 2.0 | Modelo LSTM | FlexÃ­vel, research-friendly, dinÃ¢mico |
| **FastAPI** | 0.104 | API REST | Moderno, rÃ¡pido, auto-documentado |
| **yfinance** | 0.2.28 | Coleta de dados | API gratuita e confiÃ¡vel |
| **scikit-learn** | 1.3 | Preprocessing | MinMaxScaler, mÃ©tricas |
| **Pandas** | 2.0 | ManipulaÃ§Ã£o de dados | AnÃ¡lise de sÃ©ries temporais |
| **NumPy** | 1.24 | Arrays numÃ©ricos | Performance em operaÃ§Ãµes |
| **Uvicorn** | 0.24 | ASGI server | Serve a API FastAPI |
| **Docker** | - | ContainerizaÃ§Ã£o | Deploy consistente |
| **Prometheus** | - | MÃ©tricas | Monitoramento production |
| **Loguru** | 0.7 | Logging | Logs estruturados e bonitos |
| **Pytest** | 7.4 | Testes | Framework de teste padrÃ£o |

### Stack de Deploy

```mermaid
graph TB
    subgraph "Containerization"
        DOCKER[Docker<br/>Container]
        COMPOSE[Docker Compose<br/>Orchestration]
    end
    
    subgraph "Cloud Platforms"
        RAIL[Railway<br/>Backend API]
        HF[HuggingFace Spaces<br/>UI Demo]
    end
    
    subgraph "CI/CD"
        GH[GitHub Actions<br/>Automation]
    end
    
    subgraph "Monitoring"
        PROM[Prometheus<br/>Metrics]
        LOG[Logs<br/>Files]
    end
    
    DOCKER --> COMPOSE
    COMPOSE --> RAIL
    DOCKER --> HF
    GH --> DOCKER
    RAIL --> PROM
    RAIL --> LOG
    
    style DOCKER fill:#e1f5ff
    style RAIL fill:#e8f5e9
    style HF fill:#fff4e1
```

---

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.10+** ([Download](https://www.python.org/downloads/))
- **Git** ([Download](https://git-scm.com/))
- **(Opcional) Docker** ([Download](https://www.docker.com/))

### OpÃ§Ã£o 1: InstalaÃ§Ã£o Local (Recomendado para Desenvolvimento)

#### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/your-username/previsao_acoes.git
cd previsao_acoes
```

#### 2. Crie um Ambiente Virtual

```bash
# Linux/Mac
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

#### 3. Instale as DependÃªncias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 4. Configure VariÃ¡veis de Ambiente (Opcional)

```bash
# Copie o template
cp .env.example .env

# Edite o arquivo .env
nano .env
```

Exemplo de `.env`:

```bash
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# Model Configuration
DEFAULT_STOCK_SYMBOL=AAPL
DEFAULT_START_DATE=2018-01-01
DEFAULT_END_DATE=2024-12-31

# LSTM Hyperparameters
LSTM_SEQUENCE_LENGTH=60
LSTM_EPOCHS=50
LSTM_BATCH_SIZE=32
LSTM_LEARNING_RATE=0.001

# Monitoring
LOG_LEVEL=INFO
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o com Docker

```bash
# Build e run
docker-compose up --build

# Acesse a API em http://localhost:8000
```

---

## ğŸ’» Como Usar

### 1. Treinar um Modelo

```bash
# Treinar modelo para Apple (AAPL)
python scripts/train_model.py AAPL

# Com perÃ­odo customizado
python scripts/train_model.py AAPL --start-date 2020-01-01 --end-date 2024-12-31

# Com hiperparÃ¢metros customizados
python scripts/train_model.py GOOGL --epochs 100 --batch-size 64
```

**O que acontece durante o treinamento:**

```mermaid
graph LR
    A[1. Download<br/>dados] --> B[2. Create<br/>16 features]
    B --> C[3. Normalize<br/>MinMaxScaler]
    C --> D[4. Create<br/>sequences 60d]
    D --> E[5. Train<br/>LSTM 50 epochs]
    E --> F[6. Evaluate<br/>RMSE, MAE, MAPE]
    F --> G[7. Save<br/>.pth + .pkl]
    
    style A fill:#e1f5ff
    style E fill:#fff4e1
    style G fill:#e8f5e9
```

**Output esperado:**

```
2024-12-02 10:00:00 | INFO | Loading data for AAPL
2024-12-02 10:00:05 | INFO | Successfully loaded 1756 records
2024-12-02 10:00:06 | INFO | Preprocessing data
2024-12-02 10:00:07 | INFO | Created 1696 sequences with shape (1696, 60, 16)
2024-12-02 10:00:07 | INFO | Train set: 1356 samples, Test set: 340 samples
2024-12-02 10:00:08 | INFO | Starting training for 50 epochs
2024-12-02 10:02:45 | INFO | Epoch [10/50] Train Loss: 0.002345, Val Loss: 0.002891
...
2024-12-02 10:15:23 | INFO | Training completed
2024-12-02 10:15:24 | INFO | Evaluating model
2024-12-02 10:15:25 | INFO |   RMSE: 3.45
2024-12-02 10:15:25 | INFO |   MAE: 2.67
2024-12-02 10:15:25 | INFO |   MAPE: 1.89%
2024-12-02 10:15:25 | INFO |   RÂ²: 0.9567
2024-12-02 10:15:25 | INFO |   Directional Accuracy: 76.47%
2024-12-02 10:15:26 | INFO | Model saved to models/lstm_model_AAPL.pth
âœ… Training complete!
```

### 2. Iniciar a API

```bash
# Desenvolvimento (com auto-reload)
python -m uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# ProduÃ§Ã£o (com mÃºltiplos workers)
python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

**Acesse a documentaÃ§Ã£o interativa:**

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### 3. Fazer PrevisÃµes

#### Via cURL

```bash
# PrevisÃ£o simples (1 dia Ã  frente)
curl -X POST "http://localhost:8000/api/v1/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "AAPL",
    "days_ahead": 1
  }'
```

**Response:**

```json
{
  "symbol": "AAPL",
  "current_price": 183.20,
  "predicted_price": 185.50,
  "prediction_date": "2024-12-03",
  "change_percentage": 1.25,
  "confidence": "high",
  "timestamp": "2024-12-02T10:30:00"
}
```

#### Via Python

```python
import requests

response = requests.post(
    "http://localhost:8000/api/v1/predict",
    json={"symbol": "AAPL", "days_ahead": 1}
)

data = response.json()
print(f"PreÃ§o atual: ${data['current_price']:.2f}")
print(f"PrevisÃ£o: ${data['predicted_price']:.2f}")
print(f"VariaÃ§Ã£o: {data['change_percentage']:.2f}%")
```

#### PrevisÃµes em Lote

```bash
curl -X POST "http://localhost:8000/api/v1/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "symbols": ["AAPL", "GOOGL", "MSFT"],
    "days_ahead": 1
  }'
```

### 4. Acessar Dados HistÃ³ricos

```bash
# Ãšltimos 365 dias
curl "http://localhost:8000/api/v1/stocks/AAPL/historical?limit=365"

# PreÃ§o mais recente
curl "http://localhost:8000/api/v1/stocks/AAPL/latest"
```

### 5. Verificar Status dos Modelos

```bash
# Status de todos os modelos
curl "http://localhost:8000/api/v1/models/status"

# Performance de um modelo especÃ­fico
curl "http://localhost:8000/api/v1/models/AAPL/performance"
```

### 6. Monitoramento

```bash
# Health check
curl "http://localhost:8000/api/v1/health"

# MÃ©tricas da API
curl "http://localhost:8000/api/v1/metrics"

# MÃ©tricas Prometheus
curl "http://localhost:8000/api/v1/metrics/prometheus"
```

---

## ğŸŒ API Endpoints

### DocumentaÃ§Ã£o Completa

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Request | Response |
|--------|----------|-----------|---------|----------|
| **POST** | `/api/v1/predict` | PrevisÃ£o para uma aÃ§Ã£o | `{symbol, days_ahead}` | `{predicted_price, current_price, ...}` |
| **POST** | `/api/v1/predict/batch` | PrevisÃµes em lote | `{symbols[], days_ahead}` | `{predictions[]}` |
| **GET** | `/api/v1/stocks/{symbol}/historical` | Dados histÃ³ricos | `?limit=365` | `{data[]}` |
| **GET** | `/api/v1/stocks/{symbol}/latest` | PreÃ§o atual | - | `{current_price, volume, ...}` |
| **GET** | `/api/v1/stocks/available` | AÃ§Ãµes com modelo treinado | - | `{stocks[], count}` |
| **POST** | `/api/v1/models/train` | Treinar/retreinar modelo | `{symbol, start_date, end_date}` | `{status, metrics}` |
| **GET** | `/api/v1/models/status` | Status de todos os modelos | - | `{models[], count}` |
| **GET** | `/api/v1/models/{symbol}/performance` | MÃ©tricas de um modelo | - | `{rmse, mae, mape, r2}` |
| **GET** | `/api/v1/health` | Health check | - | `{status: healthy}` |
| **GET** | `/api/v1/metrics` | MÃ©tricas da API | - | `{requests, latency, uptime}` |
| **GET** | `/api/v1/metrics/prometheus` | MÃ©tricas Prometheus | - | Formato Prometheus |

### Exemplos de Uso Completos

#### 1. Workflow Completo: Treinar e Prever

```python
import requests
import time

API_URL = "http://localhost:8000"

# 1. Treinar modelo
print("1. Treinando modelo...")
response = requests.post(
    f"{API_URL}/api/v1/models/train",
    json={
        "symbol": "AAPL",
        "start_date": "2020-01-01",
        "end_date": "2024-12-31",
        "epochs": 50
    }
)
print(f"Status: {response.json()}")

# 2. Verificar status
print("\n2. Verificando status do modelo...")
response = requests.get(f"{API_URL}/api/v1/models/status")
print(f"Modelos disponÃ­veis: {response.json()['count']}")

# 3. Ver performance
print("\n3. MÃ©tricas do modelo...")
response = requests.get(f"{API_URL}/api/v1/models/AAPL/performance")
metrics = response.json()
print(f"RMSE: {metrics['rmse']:.2f}")
print(f"MAPE: {metrics['mape']:.2f}%")

# 4. Fazer previsÃ£o
print("\n4. Fazendo previsÃ£o...")
response = requests.post(
    f"{API_URL}/api/v1/predict",
    json={"symbol": "AAPL", "days_ahead": 1}
)
pred = response.json()
print(f"PreÃ§o atual: ${pred['current_price']:.2f}")
print(f"PrevisÃ£o: ${pred['predicted_price']:.2f}")
print(f"VariaÃ§Ã£o: {pred['change_percentage']:.2f}%")
```

---

## ğŸš¢ Deploy

### 1. Deploy com Railway (Backend API)

Railway Ã© uma plataforma cloud simples e com tier gratuito.

#### Passo a Passo

```bash
# 1. Instale Railway CLI
npm i -g @railway/cli

# 2. Login
railway login

# 3. Inicialize projeto
railway init

# 4. Configure variÃ¡veis de ambiente
railway variables set DEFAULT_STOCK_SYMBOL=AAPL
railway variables set LSTM_EPOCHS=50

# 5. Deploy
railway up
```

#### Ou via GitHub (Recomendado)

1. Conecte seu repositÃ³rio no [Railway Dashboard](https://railway.app/)
2. Configure variÃ¡veis de ambiente no dashboard
3. Cada push no `main` faz deploy automaticamente

**VariÃ¡veis de ambiente necessÃ¡rias:**

```bash
API_HOST=0.0.0.0
API_PORT=8000
DEFAULT_STOCK_SYMBOL=AAPL
LSTM_EPOCHS=50
LSTM_BATCH_SIZE=32
LOG_LEVEL=INFO
```

### 2. Deploy HuggingFace Spaces (UI Demo)

HuggingFace Spaces hospeda demos Gradio gratuitamente.

#### Passo a Passo

```bash
# 1. Crie um Space em https://huggingface.co/spaces
# Escolha SDK: Gradio

# 2. Clone o space
git clone https://huggingface.co/spaces/your-username/stock-prediction

# 3. Copie arquivos necessÃ¡rios
cp app_gradio.py stock-prediction/app.py
cd stock-prediction

# 4. Crie requirements.txt especÃ­fico
cat > requirements.txt << EOF
gradio==4.0.0
requests==2.31.0
pandas==2.0.3
plotly==5.17.0
EOF

# 5. Commit e push
git add .
git commit -m "Add Gradio interface"
git push

# Space estarÃ¡ disponÃ­vel em:
# https://huggingface.co/spaces/your-username/stock-prediction
```

### 3. Deploy com Docker

#### Build e Run Local

```bash
# Build
docker build -t stock-prediction-api:latest .

# Run
docker run -d \
  --name stock-api \
  -p 8000:8000 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/data:/app/data \
  -e DEFAULT_STOCK_SYMBOL=AAPL \
  stock-prediction-api:latest

# Logs
docker logs -f stock-api
```

#### Docker Compose (Recomendado)

```bash
# Start
docker-compose up -d

# Logs
docker-compose logs -f

# Stop
docker-compose down
```

---

## ğŸ“ TÃ©cnicas de ML Engineering Aplicadas

Este projeto segue as melhores prÃ¡ticas de ML Engineering:

### 1. **Separation of Concerns**

```mermaid
graph TB
    subgraph "Data Layer"
        DL[DataLoader]
        PP[Preprocessor]
    end
    
    subgraph "Model Layer"
        MODEL[LSTM Model]
        TRAIN[Trainer]
    end
    
    subgraph "Service Layer"
        API[FastAPI]
        ROUTES[Routes]
    end
    
    subgraph "Infrastructure"
        CONFIG[Config]
        LOG[Logging]
        MON[Monitoring]
    end
    
    DL --> MODEL
    PP --> MODEL
    MODEL --> TRAIN
    TRAIN --> API
    API --> ROUTES
    CONFIG --> DL
    CONFIG --> MODEL
    CONFIG --> API
    LOG --> API
    MON --> API
    
    style MODEL fill:#fff4e1
    style API fill:#e8f5e9
```

**Cada componente tem uma responsabilidade clara:**

- `DataLoader`: Apenas coleta dados
- `Preprocessor`: Apenas transforma dados
- `LSTMModel`: Apenas define arquitetura
- `Trainer`: Apenas treina
- `API`: Apenas serve o modelo

### 2. **Configuration Management**

```python
# Todas as configuraÃ§Ãµes em um lugar
# config/settings.py

LSTM_SEQUENCE_LENGTH = int(os.getenv("LSTM_SEQUENCE_LENGTH", "60"))
LSTM_EPOCHS = int(os.getenv("LSTM_EPOCHS", "50"))
LSTM_BATCH_SIZE = int(os.getenv("LSTM_BATCH_SIZE", "32"))
```

**BenefÃ­cios:**
- âœ… Muda comportamento sem alterar cÃ³digo
- âœ… Diferentes configs para dev/prod
- âœ… FÃ¡cil de testar com configs diferentes

### 3. **Model Versioning**

```python
# Modelos salvos com metadata
{
  "symbol": "AAPL",
  "trained_at": "2024-12-02T10:15:26",
  "metrics": {
    "rmse": 3.45,
    "mae": 2.67,
    "mape": 1.89
  },
  "hyperparameters": {
    "epochs": 50,
    "batch_size": 32,
    "learning_rate": 0.001
  }
}
```

### 4. **Logging e Monitoring**

```python
# Logs estruturados
logger.info(f"Prediction for {symbol}: ${price:.2f}")

# MÃ©tricas Prometheus
metrics_collector.record_request(
    method="POST",
    endpoint="/predict",
    status=200,
    duration=0.234
)
```

### 5. **Testing**

```python
# Testes automatizados para cada componente
pytest tests/test_api.py -v
pytest tests/test_model.py -v
pytest tests/test_preprocessor.py -v
```

### 6. **Containerization**

```dockerfile
# Multi-stage build otimizado
FROM python:3.10-slim as base
# ...instala dependÃªncias...

FROM python:3.10-slim
# ...copia apenas o necessÃ¡rio...
```

### 7. **CI/CD Pipeline**

```yaml
# .github/workflows/ci-cd.yml
- name: Run tests
  run: pytest
  
- name: Build Docker
  run: docker build .
  
- name: Deploy to Railway
  if: github.ref == 'refs/heads/main'
```

### 8. **API Best Practices**

- âœ… **ValidaÃ§Ã£o** com Pydantic
- âœ… **DocumentaÃ§Ã£o automÃ¡tica** (Swagger)
- âœ… **Error handling** robusto
- âœ… **CORS** configurado
- âœ… **Health checks**
- âœ… **Versionamento** (`/api/v1`)

### 9. **Model Deployment Patterns**

```mermaid
graph LR
    A[Train Offline] --> B[Save Model]
    B --> C[Load in API]
    C --> D[Serve Predictions]
    D --> E[Monitor Performance]
    E --> F{Performance<br/>degraded?}
    F -->|Yes| A
    F -->|No| D
    
    style A fill:#fff4e1
    style D fill:#e8f5e9
```

---

## ğŸ“Š Monitoramento e Testes

### Testes Automatizados

```bash
# Todos os testes
pytest

# Com verbosidade
pytest -v

# Com cobertura
pytest --cov=src tests/

# Testes especÃ­ficos
pytest tests/test_api.py::test_prediction -v
```

### Estrutura de Testes

```
tests/
â”œâ”€â”€ test_api.py              # Testa endpoints
â”œâ”€â”€ test_data_loader.py      # Testa coleta de dados
â”œâ”€â”€ test_preprocessor.py     # Testa feature engineering
â””â”€â”€ test_model.py            # Testa LSTM
```

### Monitoramento em ProduÃ§Ã£o

#### 1. Health Checks

```bash
# Verificar se a API estÃ¡ saudÃ¡vel
curl http://localhost:8000/api/v1/health

# Response:
{
  "status": "healthy",
  "timestamp": "2024-12-02T10:30:00",
  "version": "1.0.0"
}
```

#### 2. MÃ©tricas da API

```bash
curl http://localhost:8000/api/v1/metrics

# Response:
{
  "total_requests": 1523,
  "successful_requests": 1489,
  "failed_requests": 34,
  "average_latency_ms": 234.5,
  "uptime_seconds": 86400,
  "predictions_made": 456
}
```

#### 3. MÃ©tricas Prometheus

```bash
curl http://localhost:8000/api/v1/metrics/prometheus

# Response (formato Prometheus):
# TYPE api_requests_total counter
api_requests_total{method="POST",endpoint="/predict",status="200"} 1523.0
# TYPE api_request_duration_seconds histogram
api_request_duration_seconds_bucket{le="0.1"} 456.0
```

#### 4. Logs

```bash
# Logs em tempo real
tail -f logs/app_2024-12-02.log

# Apenas erros
tail -f logs/errors_2024-12-02.log
```

---

## ğŸ“ˆ Resultados e MÃ©tricas

### MÃ©tricas de AvaliaÃ§Ã£o

O modelo Ã© avaliado usando 5 mÃ©tricas principais:

#### 1. **RMSE (Root Mean Square Error)**

```
RMSE = âˆš(Î£(predicted - actual)Â² / n)
```

- **O que mede**: Erro mÃ©dio em dÃ³lares
- **Bom valor**: < 5% do preÃ§o mÃ©dio
- **Exemplo**: RMSE de $3.45 para AAPL ($183) = 1.88%

#### 2. **MAE (Mean Absolute Error)**

```
MAE = Î£|predicted - actual| / n
```

- **O que mede**: Erro absoluto mÃ©dio
- **Bom valor**: < 3% do preÃ§o mÃ©dio
- **Exemplo**: MAE de $2.67 para AAPL = 1.46%

#### 3. **MAPE (Mean Absolute Percentage Error)**

```
MAPE = (Î£|actual - predicted| / |actual|) / n Ã— 100%
```

- **O que mede**: Erro percentual mÃ©dio
- **InterpretaÃ§Ã£o**:
  - < 10%: Excelente
  - 10-20%: Bom
  - 20-50%: AceitÃ¡vel
  - \> 50%: Ruim

#### 4. **RÂ² (Coefficient of Determination)**

```
RÂ² = 1 - (SS_res / SS_tot)
```

- **O que mede**: % da variÃ¢ncia explicada
- **InterpretaÃ§Ã£o**:
  - 0.9-1.0: Excelente
  - 0.7-0.9: Bom
  - 0.5-0.7: Moderado
  - < 0.5: Ruim

#### 5. **Directional Accuracy**

```
DA = (# direÃ§Ãµes corretas / # previsÃµes) Ã— 100%
```

- **O que mede**: % de vezes que acertou a direÃ§Ã£o (subida/descida)
- **Bom valor**: > 60%

### Exemplo de Resultados

```
=== MÃ©tricas do Modelo AAPL ===
RMSE:                    3.45
MAE:                     2.67
MAPE:                    1.89%  â† Excelente!
RÂ²:                      0.9567 â† Muito bom!
Directional Accuracy:    76.47% â† Bom!
Test Samples:            340

InterpretaÃ§Ã£o:
âœ… Modelo com boa capacidade preditiva
âœ… Erro percentual baixo (< 2%)
âœ… Alta capacidade de explicar variÃ¢ncia
âœ… Acerta direÃ§Ã£o em 3 de cada 4 casos
```

---

## ğŸ› Troubleshooting

### Problemas Comuns

#### 1. "Model not found"

**Erro:**
```
FileNotFoundError: Model file not found for symbol AAPL
```

**SoluÃ§Ã£o:**
```bash
# Treine o modelo primeiro
python scripts/train_model.py AAPL
```

#### 2. "Port already in use"

**Erro:**
```
Error: [Errno 48] Address already in use
```

**SoluÃ§Ã£o:**
```bash
# Use outra porta
uvicorn src.api.main:app --port 8001

# Ou mate o processo na porta 8000
lsof -ti:8000 | xargs kill -9
```

#### 3. "Module not found"

**Erro:**
```
ModuleNotFoundError: No module named 'src'
```

**SoluÃ§Ã£o:**
```bash
# Certifique-se de estar na raiz do projeto
cd /path/to/previsao_acoes

# E que o ambiente virtual estÃ¡ ativado
source venv/bin/activate

# Reinstale dependÃªncias
pip install -r requirements.txt
```

#### 4. "Insufficient data"

**Erro:**
```
ValueError: Need at least 60 rows, got 45
```

**SoluÃ§Ã£o:**
```bash
# Use um perÃ­odo maior (mÃ­nimo 60 dias)
python scripts/train_model.py AAPL --start-date 2024-01-01 --end-date 2024-12-31
```

#### 5. "CUDA out of memory" (GPU)

**SoluÃ§Ã£o:**
```bash
# Reduza o batch size
python scripts/train_model.py AAPL --batch-size 16

# Ou force uso de CPU
export CUDA_VISIBLE_DEVICES=""
```

---

## ğŸ“ Conceitos Aprendidos

Este projeto cobre os principais conceitos de ML Engineering:

### 1. **Data Engineering**
- Coleta de dados de APIs externas
- ValidaÃ§Ã£o e limpeza de dados
- Feature engineering (16 features tÃ©cnicas)
- NormalizaÃ§Ã£o com MinMaxScaler

### 2. **Deep Learning**
- Arquitetura LSTM (recurrent networks)
- Training loop (forward, backward, update)
- RegularizaÃ§Ã£o (dropout)
- MÃ©tricas de avaliaÃ§Ã£o

### 3. **MLOps**
- Model versioning
- Reproducibilidade
- Logging estruturado
- Monitoring com mÃ©tricas

### 4. **API Development**
- REST API com FastAPI
- ValidaÃ§Ã£o com Pydantic
- DocumentaÃ§Ã£o automÃ¡tica
- Error handling

### 5. **DevOps**
- ContainerizaÃ§Ã£o com Docker
- CI/CD com GitHub Actions
- Deploy em cloud (Railway)
- Health checks

### 6. **Software Engineering**
- Clean code
- Separation of concerns
- Testing automatizado
- Configuration management

---

## ğŸ“š PrÃ³ximos Passos

### Para Melhorar o Modelo

1. **Adicionar mais features**
   - Indicadores tÃ©cnicos (RSI, MACD, Bollinger Bands)
   - Dados de sentimento (notÃ­cias, Twitter)
   - Dados macroeconÃ´micos

2. **Experimentar outras arquiteturas**
   - Attention mechanisms
   - Transformer models
   - Ensemble de modelos

3. **Hyperparameter tuning**
   - Grid search
   - Random search
   - Optuna (Bayesian optimization)

### Para Melhorar a Infraestrutura

1. **Banco de dados**
   - PostgreSQL para histÃ³rico
   - Redis para cache
   - Timescale para sÃ©ries temporais

2. **AutenticaÃ§Ã£o**
   - JWT tokens
   - Rate limiting
   - API keys

3. **A/B Testing**
   - Testar mÃºltiplas versÃµes do modelo
   - Gradual rollout

4. **Retreinamento automÃ¡tico**
   - Agendar retreinamento semanal
   - Detectar data drift
   - Rollback automÃ¡tico se performance cair

---

## ğŸ¤ Contribuindo

Este projeto Ã© educacional e aceita contribuiÃ§Ãµes!

```bash
# 1. Fork o projeto
# 2. Crie uma branch
git checkout -b feature/nova-feature

# 3. FaÃ§a suas mudanÃ§as e commit
git commit -m "Add: nova feature incrÃ­vel"

# 4. Push para sua branch
git push origin feature/nova-feature

# 5. Abra um Pull Request
```

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¨â€ğŸ’» Autor

**Seu Nome** - Tech Challenge Fase 4 - FIAP PÃ³s-Tech MLET

- GitHub: [@seu-usuario](https://github.com/seu-usuario)
- LinkedIn: [seu-perfil](https://linkedin.com/in/seu-perfil)
- Email: seu.email@exemplo.com

---

## ğŸ™ Agradecimentos

- **FIAP** - PÃ³s-Tech Machine Learning Engineering
- **Comunidade Python** - Bibliotecas incrÃ­veis
- **Yahoo Finance** - Dados gratuitos e confiÃ¡veis
- **FastAPI** - Framework moderno e rÃ¡pido
- **PyTorch** - Deep learning flexÃ­vel

---

## âš ï¸ Disclaimer

**IMPORTANTE**: Este Ã© um projeto educacional desenvolvido para fins de aprendizado.

**NÃƒO USE** este sistema para tomar decisÃµes reais de investimento. O mercado de aÃ§Ãµes Ã© altamente volÃ¡til e imprevisÃ­vel. Modelos de ML podem ter boa performance em dados histÃ³ricos mas nÃ£o garantem resultados futuros.

**Sempre consulte um profissional financeiro qualificado antes de investir.**

---

## ğŸ“ Suporte

- **Issues**: [GitHub Issues](https://github.com/seu-usuario/previsao_acoes/issues)
- **DiscussÃµes**: [GitHub Discussions](https://github.com/seu-usuario/previsao_acoes/discussions)
- **Email**: seu.email@exemplo.com

---

**Desenvolvido com â¤ï¸ para aprender ML Engineering na prÃ¡tica**

*Ãšltima atualizaÃ§Ã£o: Dezembro 2024*

